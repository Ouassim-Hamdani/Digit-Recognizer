{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-26T18:22:09.779185Z","iopub.execute_input":"2023-06-26T18:22:09.779544Z","iopub.status.idle":"2023-06-26T18:22:18.898756Z","shell.execute_reply.started":"2023-06-26T18:22:09.779514Z","shell.execute_reply":"2023-06-26T18:22:18.897460Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Preperation","metadata":{}},{"cell_type":"code","source":"main_path = \"/kaggle/input/digit-recognizer\"\ntrain_file = pd.read_csv(os.path.join(main_path, \"train.csv\"))\ntest_file  = pd.read_csv(os.path.join(main_path, \"test.csv\"))","metadata":{"execution":{"iopub.status.busy":"2023-06-26T18:23:18.332690Z","iopub.execute_input":"2023-06-26T18:23:18.333478Z","iopub.status.idle":"2023-06-26T18:23:23.139346Z","shell.execute_reply.started":"2023-06-26T18:23:18.333447Z","shell.execute_reply":"2023-06-26T18:23:23.138385Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"n_h = n_w = 32\nn_c = 3\nm_train = len(train_file)\nm_test = len(test_file)","metadata":{"execution":{"iopub.status.busy":"2023-06-26T18:23:27.074911Z","iopub.execute_input":"2023-06-26T18:23:27.075263Z","iopub.status.idle":"2023-06-26T18:23:27.080956Z","shell.execute_reply.started":"2023-06-26T18:23:27.075234Z","shell.execute_reply":"2023-06-26T18:23:27.079956Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_images = np.zeros((m_train,n_h,n_w,n_c))\ntest_images = np.zeros((m_test,n_h,n_w,n_c))\ntrain_labels = np.array(train_file.iloc[:,0])","metadata":{"execution":{"iopub.status.busy":"2023-06-26T18:23:31.107845Z","iopub.execute_input":"2023-06-26T18:23:31.108185Z","iopub.status.idle":"2023-06-26T18:23:31.114236Z","shell.execute_reply.started":"2023-06-26T18:23:31.108157Z","shell.execute_reply":"2023-06-26T18:23:31.113244Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"for example in range(m_train):\n    for i in range(3):\n        train_images[example,:,:,i]= np.pad(train_file.iloc[example,1:].values.reshape(28,28),2,'constant')\nfor example in range(m_test):\n    for i in range(3):\n        test_images[example,:,:,i]= np.pad(test_file.iloc[example,:].values.reshape(28,28),2,'constant')\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-26T18:23:35.234363Z","iopub.execute_input":"2023-06-26T18:23:35.234744Z","iopub.status.idle":"2023-06-26T18:24:07.499822Z","shell.execute_reply.started":"2023-06-26T18:23:35.234715Z","shell.execute_reply":"2023-06-26T18:24:07.498860Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"plt.imshow(train_images[1])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-26T18:11:43.280303Z","iopub.execute_input":"2023-06-26T18:11:43.280668Z","iopub.status.idle":"2023-06-26T18:11:43.511334Z","shell.execute_reply.started":"2023-06-26T18:11:43.280638Z","shell.execute_reply":"2023-06-26T18:11:43.510437Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAanUlEQVR4nO3df2iV5/3/8dfx111/JIeKJuecGUNoY7fWH1B1mtCqcxgMTEzdwFYokYHMLgrBlnZahukGxgkVCml1a4esrJ3+MXVCrW2GJrFkjiiKwRZJMc4McxYUe06MekS9Pn/02/PtMVFzknPyzjl5PuCG5r7vnHPdXqd5cufc547POecEAICBUdYDAACMXEQIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYGWM9gPvdu3dPly9fVk5Ojnw+n/VwAABJcs6pu7tboVBIo0Y9/Fxn2EXo8uXLKigosB4GAGCQOjo6NG3atIfuk7Zfx7333nsqKirSY489prlz5+r48eP9+r6cnJx0DQkAMIT68/M8LRHat2+fqqur9eabb+r06dN6/vnnVV5erkuXLj3ye/kVHABkh/78PPel4wamCxYs0LPPPqtdu3bF1/3oRz9SRUWFamtrH/q90WhUfr8/1UMCAAyxSCSi3Nzch+6T8jOh27dv69SpUyorK0tYX1ZWpubm5l77x2IxRaPRhAUAMDKkPEJXrlzR3bt3lZ+fn7A+Pz9f4XC41/61tbXy+/3xhYsSAGDkSNuFCff/LtA51+fvBzdv3qxIJBJfOjo60jUkAMAwk/JLtKdMmaLRo0f3Ouvp6urqdXYkSZ7nyfO8VA8DAJABUn4mNG7cOM2dO1f19fUJ6+vr61VaWprqpwMAZLC0fFh106ZNevnllzVv3jyVlJToT3/6ky5duqT169en4+kAABkqLRFavXq1rl69qt/97nfq7OzUzJkzdfjwYRUWFqbj6QAAGSotnxMaDD4nBADZweRzQgAA9BcRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMJPyCNXU1Mjn8yUsgUAg1U8DAMgCY9LxoM8884z++c9/xr8ePXp0Op4GAJDh0hKhMWPGcPYDAHiktLwn1NbWplAopKKiIr344ou6cOHCA/eNxWKKRqMJCwBgZEh5hBYsWKAPP/xQn332md5//32Fw2GVlpbq6tWrfe5fW1srv98fXwoKClI9JADAMOVzzrl0PkFPT4+eeOIJvf7669q0aVOv7bFYTLFYLP51NBolRACQBSKRiHJzcx+6T1reE/q+iRMnatasWWpra+tzu+d58jwv3cMAAAxDaf+cUCwW01dffaVgMJjupwIAZJiUR+i1115TY2Oj2tvb9e9//1u/+MUvFI1GVVlZmeqnAgBkuJT/Ou6///2vXnrpJV25ckVTp07VwoULdeLECRUWFqb6qQCl+S1N3Mfn81kPAVkm7RcmJCsajcrv91sPAxlimL18sx4RQjL6c2EC944DAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNp/1MOALfWyR7JziW3+cGjcCYEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGa4bQ+Sxm140F/pfK1wS6DswJkQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADAzxnoAsOecsx4CkLRkXrc+ny+NI8FgcCYEADCTdISampq0YsUKhUIh+Xw+HTx4MGG7c041NTUKhUIaP368lixZonPnzqVqvACALJJ0hHp6ejRnzhzV1dX1uX3Hjh3auXOn6urq1NLSokAgoGXLlqm7u3vQgwUAZBefG8QbAj6fTwcOHFBFRYWkb8+CQqGQqqur9cYbb0iSYrGY8vPz9Yc//EG/+tWvHvmY0WhUfr9/oEPCAPCeELId7wnZiEQiys3Nfeg+KX1PqL29XeFwWGVlZfF1nudp8eLFam5u7vN7YrGYotFowgIAGBlSGqFwOCxJys/PT1ifn58f33a/2tpa+f3++FJQUJDKIQEAhrG0XB13/6mvc+6Bp8ObN29WJBKJLx0dHekYEgBgGErp54QCgYCkb8+IgsFgfH1XV1evs6PveJ4nz/NSOQwAQIZI6ZlQUVGRAoGA6uvr4+tu376txsZGlZaWpvKpAABZIOkzoevXr+vrr7+Of93e3q4zZ85o8uTJmj59uqqrq7Vt2zYVFxeruLhY27Zt04QJE7RmzZqUDhwAkAVcko4dO+Yk9VoqKyudc87du3fPbd261QUCAed5nlu0aJFrbW3t9+NHIpE+H58lfQuGHnM0tKz/HxupSyQSeeTcDOpzQunA54SG3jB7CYwIyX5uhTkaHD4nZGPIPycEAEAyiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMBMSv+UA4YPbvPSWybfuiWdYx8Jr5VkjzGTXyuZhjMhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADDDbXuQ0bi9yuAl8284Em7xg6HFmRAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAICZMdYDAJA5fD5fUvs759I0kvRKdtzJ/rvg/+NMCABghggBAMwkHaGmpiatWLFCoVBIPp9PBw8eTNi+du1a+Xy+hGXhwoWpGi8AIIskHaGenh7NmTNHdXV1D9xn+fLl6uzsjC+HDx8e1CABANkp6QsTysvLVV5e/tB9PM9TIBAY8KAAACNDWt4TamhoUF5enmbMmKF169apq6vrgfvGYjFFo9GEBQAwMqQ8QuXl5froo4909OhRvf3222ppadHSpUsVi8X63L+2tlZ+vz++FBQUpHpIAIBhyucGcSG/z+fTgQMHVFFR8cB9Ojs7VVhYqL1792rVqlW9tsdisYRARaNRQpQCmfr5jGTx+YzhjdfhyBaJRJSbm/vQfdL+YdVgMKjCwkK1tbX1ud3zPHmel+5hAACGobR/Tujq1avq6OhQMBhM91MBADJM0mdC169f19dffx3/ur29XWfOnNHkyZM1efJk1dTU6Oc//7mCwaAuXryoLVu2aMqUKXrhhRdSOnAAQBZwSTp27JiT1GuprKx0N27ccGVlZW7q1Klu7Nixbvr06a6ystJdunSp348fiUT6fPyRvqBv1vPCwuvWOV6HD1oikcgj/+0GdWFCOkSjUfn9futhDDvDbJqGDd4QHt5GyuuW12Hf+nNhAveOAwCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmBljPQD0j8/nS2p/51yaRjK8JHOcyf4boreR8rrC0OFMCABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMcNsejBjJ3nJmpNzmh1vx9DZS5n444EwIAGAmqQjV1tZq/vz5ysnJUV5enioqKnT+/PmEfZxzqqmpUSgU0vjx47VkyRKdO3cupYMGAGSHpCLU2NioqqoqnThxQvX19bpz547KysrU09MT32fHjh3auXOn6urq1NLSokAgoGXLlqm7uzvlgwcAZDg3CF1dXU6Sa2xsdM45d+/ePRcIBNz27dvj+9y6dcv5/X63e/fufj1mJBJxklgGuWDwrOeQ14od6znJliUSiTzy33pQ7wlFIhFJ0uTJkyVJ7e3tCofDKisri+/jeZ4WL16s5ubmPh8jFospGo0mLACAkWHAEXLOadOmTXruuec0c+ZMSVI4HJYk5efnJ+ybn58f33a/2tpa+f3++FJQUDDQIQEAMsyAI7RhwwadPXtWf/vb33ptu//yRufcAy953Lx5syKRSHzp6OgY6JAAABlmQJ8T2rhxow4dOqSmpiZNmzYtvj4QCEj69owoGAzG13d1dfU6O/qO53nyPG8gwwAAZLikzoScc9qwYYP279+vo0ePqqioKGF7UVGRAoGA6uvr4+tu376txsZGlZaWpmbEAICskdSZUFVVlT7++GP94x//UE5OTvx9Hr/fr/Hjx8vn86m6ulrbtm1TcXGxiouLtW3bNk2YMEFr1qxJywEAADKX7/9djti/nR/wvs6ePXu0du1aSd+eLb311lv64x//qGvXrmnBggV699134xcvPEo0GpXf7+/vkPAASUwrHmCk3LqF10pvI2Xu0y0SiSg3N/eh+yQVoaFAhIbeMHsJAClHVGz0J0LcOw4AYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzAzoTzkguyR7SxNu8wMgVTgTAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIZ7xyFp3GsOQKpwJgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZrhtD4BhIdnbQSE7cCYEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADPeOQ9olc08w51waR4Khxv3g8CicCQEAzCQVodraWs2fP185OTnKy8tTRUWFzp8/n7DP2rVr5fP5EpaFCxemdNAAgOyQVIQaGxtVVVWlEydOqL6+Xnfu3FFZWZl6enoS9lu+fLk6Ozvjy+HDh1M6aABAdkjqPaEjR44kfL1nzx7l5eXp1KlTWrRoUXy953kKBAKpGSEAIGsN6j2hSCQiSZo8eXLC+oaGBuXl5WnGjBlat26durq6HvgYsVhM0Wg0YQEAjAw+N8DLkZxzWrlypa5du6bjx4/H1+/bt0+TJk1SYWGh2tvb9dvf/lZ37tzRqVOn5Hler8epqanRW2+9NfAjQFbh6rjswtVxI1skElFubu5D9xlwhKqqqvTJJ5/oiy++0LRp0x64X2dnpwoLC7V3716tWrWq1/ZYLKZYLBb/OhqNqqCgYCBDQhYgQtmFCI1s/YnQgD4ntHHjRh06dEhNTU0PDZAkBYNBFRYWqq2trc/tnuf1eYYEAMh+SUXIOaeNGzfqwIEDamhoUFFR0SO/5+rVq+ro6FAwGBzwIAEA2SmpCxOqqqr017/+VR9//LFycnIUDocVDod18+ZNSdL169f12muv6V//+pcuXryohoYGrVixQlOmTNELL7yQlgMAAGSupN4TetDvd/fs2aO1a9fq5s2bqqio0OnTp/XNN98oGAzqJz/5iX7/+9/3+32eaDQqv9/f3yEhy/CeUHbhPaGRLa0XJqQLEQKA7NCfCHHvOACAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABgJqkI7dq1S7Nnz1Zubq5yc3NVUlKiTz/9NL7dOaeamhqFQiGNHz9eS5Ys0blz51I+aABAdkgqQtOmTdP27dt18uRJnTx5UkuXLtXKlSvjodmxY4d27typuro6tbS0KBAIaNmyZeru7k7L4AEAGc4N0uOPP+4++OADd+/ePRcIBNz27dvj227duuX8fr/bvXt3vx8vEok4SSwsLCwsGb5EIpFH/swf8HtCd+/e1d69e9XT06OSkhK1t7crHA6rrKwsvo/neVq8eLGam5sf+DixWEzRaDRhAQCMDElHqLW1VZMmTZLneVq/fr0OHDigp59+WuFwWJKUn5+fsH9+fn58W19qa2vl9/vjS0FBQbJDAgBkqKQj9NRTT+nMmTM6ceKEXnnlFVVWVurLL7+Mb/f5fAn7O+d6rfu+zZs3KxKJxJeOjo5khwQAyFBjkv2GcePG6cknn5QkzZs3Ty0tLXrnnXf0xhtvSJLC4bCCwWB8/66url5nR9/neZ48z0t2GACALDDozwk55xSLxVRUVKRAIKD6+vr4ttu3b6uxsVGlpaWDfRoAQBZK6kxoy5YtKi8vV0FBgbq7u7V37141NDToyJEj8vl8qq6u1rZt21RcXKzi4mJt27ZNEyZM0Jo1a9I1fgBABksqQv/73//08ssvq7OzU36/X7Nnz9aRI0e0bNkySdLrr7+umzdv6te//rWuXbumBQsW6PPPP1dOTk5aBg8AyGw+55yzHsT3RaNR+f1+62EAAAYpEokoNzf3oftw7zgAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAICZYRehYXYDBwDAAPXn5/mwi1B3d7f1EAAAKdCfn+fD7t5x9+7d0+XLl5WTk5Pwx/Ci0agKCgrU0dHxyHsRZTKOM3uMhGOUOM5sk4rjdM6pu7tboVBIo0Y9/Fwn6T9ql26jRo3StGnTHrg9Nzc3q18A3+E4s8dIOEaJ48w2gz3O/t6Ietj9Og4AMHIQIQCAmYyJkOd52rp1qzzPsx5KWnGc2WMkHKPEcWaboT7OYXdhAgBg5MiYMyEAQPYhQgAAM0QIAGCGCAEAzGRMhN577z0VFRXpscce09y5c3X8+HHrIaVUTU2NfD5fwhIIBKyHNShNTU1asWKFQqGQfD6fDh48mLDdOaeamhqFQiGNHz9eS5Ys0blz52wGOwiPOs61a9f2mtuFCxfaDHaAamtrNX/+fOXk5CgvL08VFRU6f/58wj7ZMJ/9Oc5smM9du3Zp9uzZ8Q+klpSU6NNPP41vH8q5zIgI7du3T9XV1XrzzTd1+vRpPf/88yovL9elS5esh5ZSzzzzjDo7O+NLa2ur9ZAGpaenR3PmzFFdXV2f23fs2KGdO3eqrq5OLS0tCgQCWrZsWcbdP/BRxylJy5cvT5jbw4cPD+EIB6+xsVFVVVU6ceKE6uvrdefOHZWVlamnpye+TzbMZ3+OU8r8+Zw2bZq2b9+ukydP6uTJk1q6dKlWrlwZD82QzqXLAD/+8Y/d+vXrE9b98Ic/dL/5zW+MRpR6W7dudXPmzLEeRtpIcgcOHIh/fe/ePRcIBNz27dvj627duuX8fr/bvXu3wQhT4/7jdM65yspKt3LlSpPxpEtXV5eT5BobG51z2Tuf9x+nc9k5n8459/jjj7sPPvhgyOdy2J8J3b59W6dOnVJZWVnC+rKyMjU3NxuNKj3a2toUCoVUVFSkF198URcuXLAeUtq0t7crHA4nzKvneVq8eHHWzaskNTQ0KC8vTzNmzNC6devU1dVlPaRBiUQikqTJkydLyt75vP84v5NN83n37l3t3btXPT09KikpGfK5HPYRunLliu7evav8/PyE9fn5+QqHw0ajSr0FCxboww8/1Geffab3339f4XBYpaWlunr1qvXQ0uK7ucv2eZWk8vJyffTRRzp69KjefvtttbS0aOnSpYrFYtZDGxDnnDZt2qTnnntOM2fOlJSd89nXcUrZM5+tra2aNGmSPM/T+vXrdeDAAT399NNDPpfD7i7aD/L9P+sgffsCuX9dJisvL4//96xZs1RSUqInnnhCf/nLX7Rp0ybDkaVXts+rJK1evTr+3zNnztS8efNUWFioTz75RKtWrTIc2cBs2LBBZ8+e1RdffNFrWzbN54OOM1vm86mnntKZM2f0zTff6O9//7sqKyvV2NgY3z5Ucznsz4SmTJmi0aNH9ypwV1dXr1Jnk4kTJ2rWrFlqa2uzHkpafHfl30ibV0kKBoMqLCzMyLnduHGjDh06pGPHjiX8yZVsm88HHWdfMnU+x40bpyeffFLz5s1TbW2t5syZo3feeWfI53LYR2jcuHGaO3eu6uvrE9bX19ertLTUaFTpF4vF9NVXXykYDFoPJS2KiooUCAQS5vX27dtqbGzM6nmVpKtXr6qjoyOj5tY5pw0bNmj//v06evSoioqKErZny3w+6jj7konz2RfnnGKx2NDPZcovdUiDvXv3urFjx7o///nP7ssvv3TV1dVu4sSJ7uLFi9ZDS5lXX33VNTQ0uAsXLrgTJ064n/3sZy4nJyejj7G7u9udPn3anT592klyO3fudKdPn3b/+c9/nHPObd++3fn9frd//37X2trqXnrpJRcMBl00GjUeeXIedpzd3d3u1Vdfdc3Nza69vd0dO3bMlZSUuB/84AcZdZyvvPKK8/v9rqGhwXV2dsaXGzduxPfJhvl81HFmy3xu3rzZNTU1ufb2dnf27Fm3ZcsWN2rUKPf5558754Z2LjMiQs459+6777rCwkI3btw49+yzzyZcMpkNVq9e7YLBoBs7dqwLhUJu1apV7ty5c9bDGpRjx445Sb2WyspK59y3l/Vu3brVBQIB53meW7RokWttbbUd9AA87Dhv3LjhysrK3NSpU93YsWPd9OnTXWVlpbt06ZL1sJPS1/FJcnv27Invkw3z+ajjzJb5/OUvfxn/eTp16lT305/+NB4g54Z2LvlTDgAAM8P+PSEAQPYiQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMz8H4D25bZcC56dAAAAAElFTkSuQmCC"},"metadata":{}}]},{"cell_type":"code","source":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=27,\n    width_shift_range=0.3,\n    height_shift_range=0.2,\n    shear_range=0.3,\n    zoom_range=0.2,\n    horizontal_flip=False)\nval_datagen = tf.keras.preprocessing.image.ImageDataGenerator()","metadata":{"execution":{"iopub.status.busy":"2023-06-26T18:24:07.510778Z","iopub.execute_input":"2023-06-26T18:24:07.511198Z","iopub.status.idle":"2023-06-26T18:24:07.517810Z","shell.execute_reply.started":"2023-06-26T18:24:07.511164Z","shell.execute_reply":"2023-06-26T18:24:07.516741Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_images.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-26T18:27:07.001811Z","iopub.execute_input":"2023-06-26T18:27:07.002298Z","iopub.status.idle":"2023-06-26T18:27:07.010738Z","shell.execute_reply.started":"2023-06-26T18:27:07.002240Z","shell.execute_reply":"2023-06-26T18:27:07.009788Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(42000, 32, 32, 3)"},"metadata":{}}]},{"cell_type":"code","source":"train_images, val_images, train_labels, val_labels = train_test_split(train_images, \n                                                                      train_labels,\n                                                                      test_size=0.1, train_size=0.9,\n                                                                      shuffle=True,\n                                                                      random_state=44)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-26T18:27:09.394597Z","iopub.execute_input":"2023-06-26T18:27:09.394947Z","iopub.status.idle":"2023-06-26T18:27:09.765968Z","shell.execute_reply.started":"2023-06-26T18:27:09.394917Z","shell.execute_reply":"2023-06-26T18:27:09.764989Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# VGG-16 Model Building","metadata":{}},{"cell_type":"code","source":"pre_model = tf.keras.applications.VGG16(input_shape=(32,32,n_c),include_top=False,weights=\"imagenet\")","metadata":{"execution":{"iopub.status.busy":"2023-06-26T18:27:16.354958Z","iopub.execute_input":"2023-06-26T18:27:16.355473Z","iopub.status.idle":"2023-06-26T18:27:19.934637Z","shell.execute_reply.started":"2023-06-26T18:27:16.355434Z","shell.execute_reply":"2023-06-26T18:27:19.933637Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58889256/58889256 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"pre_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-26T18:27:32.045188Z","iopub.execute_input":"2023-06-26T18:27:32.045541Z","iopub.status.idle":"2023-06-26T18:27:32.082836Z","shell.execute_reply.started":"2023-06-26T18:27:32.045512Z","shell.execute_reply":"2023-06-26T18:27:32.082105Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Model: \"vgg16\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n                                                                 \n=================================================================\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    pre_model,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units=1024,activation='relu'),\n    tf.keras.layers.Dense(units=64,activation='relu'),\n    tf.keras.layers.Dense(units=32,activation='relu'),\n    tf.keras.layers.Dense(units=10,activation='softmax')\n    \n])","metadata":{"execution":{"iopub.status.busy":"2023-06-26T19:13:49.204907Z","iopub.execute_input":"2023-06-26T19:13:49.205284Z","iopub.status.idle":"2023-06-26T19:13:49.335327Z","shell.execute_reply.started":"2023-06-26T19:13:49.205256Z","shell.execute_reply":"2023-06-26T19:13:49.334331Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n             loss='sparse_categorical_crossentropy',\n              metrics=[\"accuracy\"]\n             )","metadata":{"execution":{"iopub.status.busy":"2023-06-26T19:13:53.910249Z","iopub.execute_input":"2023-06-26T19:13:53.910810Z","iopub.status.idle":"2023-06-26T19:13:53.927738Z","shell.execute_reply.started":"2023-06-26T19:13:53.910765Z","shell.execute_reply":"2023-06-26T19:13:53.926781Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_datagen.flow(train_images,train_labels, batch_size=200),\n                         steps_per_epoch=train_images.shape[0] / 200, \n                         epochs=50,   \n                         validation_data=val_datagen.flow(val_images,val_labels,\n                                                                 batch_size=200\n                        ))","metadata":{"execution":{"iopub.status.busy":"2023-06-26T19:19:51.772455Z","iopub.execute_input":"2023-06-26T19:19:51.773286Z","iopub.status.idle":"2023-06-26T19:46:21.090033Z","shell.execute_reply.started":"2023-06-26T19:19:51.773243Z","shell.execute_reply":"2023-06-26T19:46:21.088985Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch 1/50\n189/189 [==============================] - 25s 130ms/step - loss: 0.0472 - accuracy: 0.9888 - val_loss: 0.0496 - val_accuracy: 0.9898\nEpoch 2/50\n189/189 [==============================] - 25s 131ms/step - loss: 0.0472 - accuracy: 0.9889 - val_loss: 0.0421 - val_accuracy: 0.9907\nEpoch 3/50\n189/189 [==============================] - 24s 128ms/step - loss: 0.0485 - accuracy: 0.9880 - val_loss: 0.0460 - val_accuracy: 0.9921\nEpoch 4/50\n189/189 [==============================] - 24s 129ms/step - loss: 0.0480 - accuracy: 0.9881 - val_loss: 0.0490 - val_accuracy: 0.9912\nEpoch 5/50\n189/189 [==============================] - 24s 129ms/step - loss: 0.0418 - accuracy: 0.9901 - val_loss: 0.0458 - val_accuracy: 0.9910\nEpoch 6/50\n189/189 [==============================] - 24s 129ms/step - loss: 0.0475 - accuracy: 0.9888 - val_loss: 0.0339 - val_accuracy: 0.9931\nEpoch 7/50\n189/189 [==============================] - 24s 128ms/step - loss: 0.0514 - accuracy: 0.9878 - val_loss: 0.0705 - val_accuracy: 0.9871\nEpoch 8/50\n189/189 [==============================] - 24s 129ms/step - loss: 0.0484 - accuracy: 0.9884 - val_loss: 0.0323 - val_accuracy: 0.9929\nEpoch 9/50\n189/189 [==============================] - 25s 130ms/step - loss: 0.0511 - accuracy: 0.9877 - val_loss: 0.0496 - val_accuracy: 0.9914\nEpoch 10/50\n189/189 [==============================] - 25s 130ms/step - loss: 0.0616 - accuracy: 0.9861 - val_loss: 0.0582 - val_accuracy: 0.9886\nEpoch 11/50\n189/189 [==============================] - 24s 126ms/step - loss: 0.0589 - accuracy: 0.9860 - val_loss: 0.0728 - val_accuracy: 0.9874\nEpoch 12/50\n189/189 [==============================] - 24s 125ms/step - loss: 0.0502 - accuracy: 0.9883 - val_loss: 0.0559 - val_accuracy: 0.9881\nEpoch 13/50\n189/189 [==============================] - 24s 127ms/step - loss: 0.0549 - accuracy: 0.9876 - val_loss: 0.0590 - val_accuracy: 0.9860\nEpoch 14/50\n189/189 [==============================] - 24s 125ms/step - loss: 0.0440 - accuracy: 0.9893 - val_loss: 0.0600 - val_accuracy: 0.9871\nEpoch 15/50\n189/189 [==============================] - 24s 126ms/step - loss: 0.0420 - accuracy: 0.9901 - val_loss: 0.0980 - val_accuracy: 0.9838\nEpoch 16/50\n189/189 [==============================] - 24s 125ms/step - loss: 0.0427 - accuracy: 0.9898 - val_loss: 0.0848 - val_accuracy: 0.9831\nEpoch 17/50\n189/189 [==============================] - 24s 124ms/step - loss: 0.0444 - accuracy: 0.9897 - val_loss: 0.0505 - val_accuracy: 0.9893\nEpoch 18/50\n189/189 [==============================] - 23s 122ms/step - loss: 0.0522 - accuracy: 0.9872 - val_loss: 0.0676 - val_accuracy: 0.9876\nEpoch 19/50\n189/189 [==============================] - 24s 126ms/step - loss: 0.0464 - accuracy: 0.9893 - val_loss: 0.0627 - val_accuracy: 0.9886\nEpoch 20/50\n189/189 [==============================] - 24s 128ms/step - loss: 0.0545 - accuracy: 0.9873 - val_loss: 0.0412 - val_accuracy: 0.9910\nEpoch 21/50\n189/189 [==============================] - 24s 126ms/step - loss: 0.0388 - accuracy: 0.9907 - val_loss: 0.0377 - val_accuracy: 0.9921\nEpoch 22/50\n189/189 [==============================] - 24s 128ms/step - loss: 0.0659 - accuracy: 0.9852 - val_loss: 0.0763 - val_accuracy: 0.9871\nEpoch 23/50\n189/189 [==============================] - 24s 127ms/step - loss: 0.0646 - accuracy: 0.9864 - val_loss: 0.0618 - val_accuracy: 0.9912\nEpoch 24/50\n189/189 [==============================] - 24s 127ms/step - loss: 0.0466 - accuracy: 0.9892 - val_loss: 0.0371 - val_accuracy: 0.9924\nEpoch 25/50\n189/189 [==============================] - 24s 128ms/step - loss: 0.0404 - accuracy: 0.9904 - val_loss: 0.0549 - val_accuracy: 0.9912\nEpoch 26/50\n189/189 [==============================] - 24s 127ms/step - loss: 0.0362 - accuracy: 0.9911 - val_loss: 0.0480 - val_accuracy: 0.9914\nEpoch 27/50\n189/189 [==============================] - 24s 127ms/step - loss: 0.0391 - accuracy: 0.9908 - val_loss: 0.0450 - val_accuracy: 0.9929\nEpoch 28/50\n189/189 [==============================] - 24s 127ms/step - loss: 0.0381 - accuracy: 0.9911 - val_loss: 0.0353 - val_accuracy: 0.9929\nEpoch 29/50\n189/189 [==============================] - 24s 128ms/step - loss: 0.0364 - accuracy: 0.9917 - val_loss: 0.0401 - val_accuracy: 0.9905\nEpoch 30/50\n189/189 [==============================] - 23s 124ms/step - loss: 0.0336 - accuracy: 0.9920 - val_loss: 0.0408 - val_accuracy: 0.9914\nEpoch 31/50\n189/189 [==============================] - 24s 128ms/step - loss: 0.0320 - accuracy: 0.9921 - val_loss: 0.0475 - val_accuracy: 0.9917\nEpoch 32/50\n189/189 [==============================] - 24s 127ms/step - loss: 0.0377 - accuracy: 0.9910 - val_loss: 0.0376 - val_accuracy: 0.9910\nEpoch 33/50\n189/189 [==============================] - 24s 128ms/step - loss: 0.0362 - accuracy: 0.9916 - val_loss: 0.0482 - val_accuracy: 0.9917\nEpoch 34/50\n189/189 [==============================] - 24s 127ms/step - loss: 0.0509 - accuracy: 0.9885 - val_loss: 0.0660 - val_accuracy: 0.9829\nEpoch 35/50\n189/189 [==============================] - 24s 126ms/step - loss: 0.0469 - accuracy: 0.9894 - val_loss: 0.0532 - val_accuracy: 0.9886\nEpoch 36/50\n189/189 [==============================] - 23s 123ms/step - loss: 0.0384 - accuracy: 0.9910 - val_loss: 0.0418 - val_accuracy: 0.9919\nEpoch 37/50\n189/189 [==============================] - 24s 125ms/step - loss: 0.0338 - accuracy: 0.9917 - val_loss: 0.0427 - val_accuracy: 0.9912\nEpoch 38/50\n189/189 [==============================] - 24s 125ms/step - loss: 0.0370 - accuracy: 0.9915 - val_loss: 0.0486 - val_accuracy: 0.9914\nEpoch 39/50\n189/189 [==============================] - 24s 126ms/step - loss: 0.0339 - accuracy: 0.9926 - val_loss: 0.0415 - val_accuracy: 0.9921\nEpoch 40/50\n189/189 [==============================] - 23s 123ms/step - loss: 0.0329 - accuracy: 0.9916 - val_loss: 0.0382 - val_accuracy: 0.9907\nEpoch 41/50\n189/189 [==============================] - 24s 125ms/step - loss: 0.0509 - accuracy: 0.9892 - val_loss: 0.0404 - val_accuracy: 0.9905\nEpoch 42/50\n189/189 [==============================] - 24s 127ms/step - loss: 0.0388 - accuracy: 0.9911 - val_loss: 0.0358 - val_accuracy: 0.9943\nEpoch 43/50\n189/189 [==============================] - 24s 126ms/step - loss: 0.0469 - accuracy: 0.9895 - val_loss: 0.0337 - val_accuracy: 0.9924\nEpoch 44/50\n189/189 [==============================] - 24s 125ms/step - loss: 0.0393 - accuracy: 0.9903 - val_loss: 0.0533 - val_accuracy: 0.9900\nEpoch 45/50\n189/189 [==============================] - 24s 126ms/step - loss: 0.0350 - accuracy: 0.9914 - val_loss: 0.0570 - val_accuracy: 0.9898\nEpoch 46/50\n189/189 [==============================] - 24s 126ms/step - loss: 0.0336 - accuracy: 0.9919 - val_loss: 0.0391 - val_accuracy: 0.9917\nEpoch 47/50\n189/189 [==============================] - 24s 128ms/step - loss: 0.0355 - accuracy: 0.9918 - val_loss: 0.0361 - val_accuracy: 0.9917\nEpoch 48/50\n189/189 [==============================] - 25s 130ms/step - loss: 0.0326 - accuracy: 0.9920 - val_loss: 0.0528 - val_accuracy: 0.9902\nEpoch 49/50\n189/189 [==============================] - 24s 128ms/step - loss: 0.0370 - accuracy: 0.9914 - val_loss: 0.0455 - val_accuracy: 0.9919\nEpoch 50/50\n189/189 [==============================] - 24s 126ms/step - loss: 0.0371 - accuracy: 0.9914 - val_loss: 0.9931 - val_accuracy: 0.9929\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model 2 Building","metadata":{}},{"cell_type":"code","source":"pre_model_2 = tf.keras.applications.ResNet50(input_shape=(32,32,n_c),include_top=False,weights=\"imagenet\")","metadata":{"execution":{"iopub.status.busy":"2023-06-26T19:54:03.677139Z","iopub.execute_input":"2023-06-26T19:54:03.677739Z","iopub.status.idle":"2023-06-26T19:54:06.348698Z","shell.execute_reply.started":"2023-06-26T19:54:03.677697Z","shell.execute_reply":"2023-06-26T19:54:06.347671Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94765736/94765736 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"pre_model_2.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-26T19:54:15.976362Z","iopub.execute_input":"2023-06-26T19:54:15.976837Z","iopub.status.idle":"2023-06-26T19:54:16.407489Z","shell.execute_reply.started":"2023-06-26T19:54:15.976798Z","shell.execute_reply":"2023-06-26T19:54:16.406477Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Model: \"resnet50\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n                                                                                                  \n conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_2[0][0]']                \n                                                                                                  \n conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n                                                                                                  \n conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n                                                                                                  \n conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n                                                                                                  \n pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n                                                                                                  \n pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n                                                                                                  \n conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n                                                                                                  \n conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n                                                                                                  \n conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n                                                                                                  \n conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n                                                                                                  \n conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n                                                                  'conv2_block1_3_bn[0][0]']      \n                                                                                                  \n conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n                                                                                                  \n conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n                                                                                                  \n conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n                                                                                                  \n conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n                                                                                                  \n conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n                                                                  'conv2_block2_3_bn[0][0]']      \n                                                                                                  \n conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n                                                                                                  \n conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n                                                                                                  \n conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n                                                                                                  \n conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n                                                                                                  \n conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n                                                                  'conv2_block3_3_bn[0][0]']      \n                                                                                                  \n conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n                                                                                                  \n conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n                                                                                                  \n conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n                                                                                                  \n conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n                                                                                                  \n conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n                                                                                                  \n conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n                                                                  'conv3_block1_3_bn[0][0]']      \n                                                                                                  \n conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n                                                                                                  \n conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n                                                                                                  \n conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n                                                                                                  \n conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n                                                                                                  \n conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n                                                                  'conv3_block2_3_bn[0][0]']      \n                                                                                                  \n conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n                                                                                                  \n conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n                                                                                                  \n conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n                                                                                                  \n conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n                                                                                                  \n conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n                                                                  'conv3_block3_3_bn[0][0]']      \n                                                                                                  \n conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n                                                                                                  \n conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n                                                                                                  \n conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n                                                                                                  \n conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n                                                                                                  \n conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n                                                                  'conv3_block4_3_bn[0][0]']      \n                                                                                                  \n conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n                                                                                                  \n conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n                                                                                                  \n conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n                                                                                                  \n conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n                                                                                                  \n conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n                                                                                                  \n conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n                                                                  'conv4_block1_3_bn[0][0]']      \n                                                                                                  \n conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n                                                                                                  \n conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n                                                                                                  \n conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n                                                                                                  \n conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n                                                                                                  \n conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n                                                                  'conv4_block2_3_bn[0][0]']      \n                                                                                                  \n conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n                                                                                                  \n conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n                                                                                                  \n conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n                                                                                                  \n conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n                                                                                                  \n conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n                                                                  'conv4_block3_3_bn[0][0]']      \n                                                                                                  \n conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n                                                                                                  \n conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n                                                                                                  \n conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n                                                                                                  \n conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n                                                                                                  \n conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n                                                                  'conv4_block4_3_bn[0][0]']      \n                                                                                                  \n conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n                                                                                                  \n conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n                                                                                                  \n conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n                                                                                                  \n conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n                                                                                                  \n conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n                                                                  'conv4_block5_3_bn[0][0]']      \n                                                                                                  \n conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n                                                                                                  \n conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n                                                                                                  \n conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n                                                                                                  \n conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv4_block6_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n                                                                                                  \n conv4_block6_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv4_block6_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block5_out[0][0]',       \n                                                                  'conv4_block6_3_bn[0][0]']      \n                                                                                                  \n conv4_block6_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block6_add[0][0]']       \n                                                                                                  \n conv5_block1_1_conv (Conv2D)   (None, 1, 1, 512)    524800      ['conv4_block6_out[0][0]']       \n                                                                                                  \n conv5_block1_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block1_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block1_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n                                                                                                  \n conv5_block1_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block1_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block1_0_conv (Conv2D)   (None, 1, 1, 2048)   2099200     ['conv4_block6_out[0][0]']       \n                                                                                                  \n conv5_block1_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n                                                                                                  \n conv5_block1_0_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block1_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block1_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n                                                                  'conv5_block1_3_bn[0][0]']      \n                                                                                                  \n conv5_block1_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block1_add[0][0]']       \n                                                                                                  \n conv5_block2_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block1_out[0][0]']       \n                                                                                                  \n conv5_block2_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block2_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block2_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n                                                                                                  \n conv5_block2_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block2_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block2_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n                                                                                                  \n conv5_block2_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block2_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_out[0][0]',       \n                                                                  'conv5_block2_3_bn[0][0]']      \n                                                                                                  \n conv5_block2_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block2_add[0][0]']       \n                                                                                                  \n conv5_block3_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block2_out[0][0]']       \n                                                                                                  \n conv5_block3_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block3_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_1_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block3_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n                                                                                                  \n conv5_block3_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block3_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_2_bn[0][0]']      \n n)                                                                                               \n                                                                                                  \n conv5_block3_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n                                                                                                  \n conv5_block3_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n ization)                                                                                         \n                                                                                                  \n conv5_block3_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block2_out[0][0]',       \n                                                                  'conv5_block3_3_bn[0][0]']      \n                                                                                                  \n conv5_block3_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block3_add[0][0]']       \n                                                                                                  \n==================================================================================================\nTotal params: 23,587,712\nTrainable params: 23,534,592\nNon-trainable params: 53,120\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_2 = tf.keras.Sequential([\n    pre_model_2,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(units=1024,activation='relu'),\n    tf.keras.layers.Dense(units=64,activation='relu'),\n    tf.keras.layers.Dense(units=10,activation='softmax')\n    \n])","metadata":{"execution":{"iopub.status.busy":"2023-06-26T19:54:44.481717Z","iopub.execute_input":"2023-06-26T19:54:44.482461Z","iopub.status.idle":"2023-06-26T19:54:45.015934Z","shell.execute_reply.started":"2023-06-26T19:54:44.482422Z","shell.execute_reply":"2023-06-26T19:54:45.014957Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"model_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n             loss='sparse_categorical_crossentropy',\n              metrics=[\"accuracy\"]\n             )","metadata":{"execution":{"iopub.status.busy":"2023-06-26T19:54:49.645561Z","iopub.execute_input":"2023-06-26T19:54:49.645948Z","iopub.status.idle":"2023-06-26T19:54:49.664818Z","shell.execute_reply.started":"2023-06-26T19:54:49.645918Z","shell.execute_reply":"2023-06-26T19:54:49.663764Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"history_2 = model_2.fit(train_datagen.flow(train_images,train_labels, batch_size=200),\n                         steps_per_epoch=train_images.shape[0] / 200, \n                         epochs=50,   \n                         validation_data=val_datagen.flow(val_images,val_labels,\n                                                                 batch_size=200\n                        ))","metadata":{"execution":{"iopub.status.busy":"2023-06-26T19:54:58.137496Z","iopub.execute_input":"2023-06-26T19:54:58.137883Z","iopub.status.idle":"2023-06-26T20:21:31.843132Z","shell.execute_reply.started":"2023-06-26T19:54:58.137854Z","shell.execute_reply":"2023-06-26T20:21:31.842198Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Epoch 1/50\n189/189 [==============================] - 66s 143ms/step - loss: 0.4653 - accuracy: 0.8636 - val_loss: 0.2704 - val_accuracy: 0.9510\nEpoch 2/50\n189/189 [==============================] - 26s 139ms/step - loss: 0.1581 - accuracy: 0.9565 - val_loss: 0.2093 - val_accuracy: 0.9574\nEpoch 3/50\n189/189 [==============================] - 26s 137ms/step - loss: 0.1404 - accuracy: 0.9631 - val_loss: 0.1396 - val_accuracy: 0.9671\nEpoch 4/50\n189/189 [==============================] - 26s 139ms/step - loss: 0.1258 - accuracy: 0.9656 - val_loss: 20.2968 - val_accuracy: 0.7629\nEpoch 5/50\n189/189 [==============================] - 26s 139ms/step - loss: 0.1239 - accuracy: 0.9663 - val_loss: 0.1168 - val_accuracy: 0.9693\nEpoch 6/50\n189/189 [==============================] - 26s 138ms/step - loss: 0.0921 - accuracy: 0.9733 - val_loss: 0.0649 - val_accuracy: 0.9831\nEpoch 7/50\n189/189 [==============================] - 26s 137ms/step - loss: 0.0844 - accuracy: 0.9766 - val_loss: 0.0958 - val_accuracy: 0.9752\nEpoch 8/50\n189/189 [==============================] - 26s 138ms/step - loss: 0.0825 - accuracy: 0.9768 - val_loss: 0.0887 - val_accuracy: 0.9771\nEpoch 9/50\n189/189 [==============================] - 26s 135ms/step - loss: 0.0785 - accuracy: 0.9783 - val_loss: 0.0711 - val_accuracy: 0.9776\nEpoch 10/50\n189/189 [==============================] - 26s 138ms/step - loss: 0.0810 - accuracy: 0.9776 - val_loss: 0.0973 - val_accuracy: 0.9743\nEpoch 11/50\n189/189 [==============================] - 25s 133ms/step - loss: 0.0764 - accuracy: 0.9776 - val_loss: 0.1743 - val_accuracy: 0.9448\nEpoch 12/50\n189/189 [==============================] - 26s 137ms/step - loss: 0.0712 - accuracy: 0.9803 - val_loss: 0.0940 - val_accuracy: 0.9779\nEpoch 13/50\n189/189 [==============================] - 26s 137ms/step - loss: 0.0732 - accuracy: 0.9797 - val_loss: 0.1022 - val_accuracy: 0.9721\nEpoch 14/50\n189/189 [==============================] - 26s 136ms/step - loss: 0.0696 - accuracy: 0.9806 - val_loss: 0.0498 - val_accuracy: 0.9869\nEpoch 15/50\n189/189 [==============================] - 26s 139ms/step - loss: 0.0631 - accuracy: 0.9823 - val_loss: 0.0694 - val_accuracy: 0.9795\nEpoch 16/50\n189/189 [==============================] - 26s 140ms/step - loss: 0.0666 - accuracy: 0.9810 - val_loss: 0.0713 - val_accuracy: 0.9781\nEpoch 17/50\n189/189 [==============================] - 27s 141ms/step - loss: 0.0614 - accuracy: 0.9823 - val_loss: 0.0397 - val_accuracy: 0.9876\nEpoch 18/50\n189/189 [==============================] - 27s 140ms/step - loss: 0.0634 - accuracy: 0.9829 - val_loss: 0.1196 - val_accuracy: 0.9664\nEpoch 19/50\n189/189 [==============================] - 26s 139ms/step - loss: 0.0660 - accuracy: 0.9810 - val_loss: 0.1746 - val_accuracy: 0.9588\nEpoch 20/50\n189/189 [==============================] - 27s 142ms/step - loss: 0.0644 - accuracy: 0.9821 - val_loss: 0.0820 - val_accuracy: 0.9776\nEpoch 21/50\n189/189 [==============================] - 26s 139ms/step - loss: 0.0573 - accuracy: 0.9842 - val_loss: 0.1093 - val_accuracy: 0.9731\nEpoch 22/50\n189/189 [==============================] - 27s 141ms/step - loss: 0.0608 - accuracy: 0.9830 - val_loss: 18.9562 - val_accuracy: 0.7286\nEpoch 23/50\n189/189 [==============================] - 27s 142ms/step - loss: 0.4541 - accuracy: 0.9008 - val_loss: 146.9434 - val_accuracy: 0.6881\nEpoch 24/50\n189/189 [==============================] - 27s 143ms/step - loss: 0.1271 - accuracy: 0.9638 - val_loss: 0.0949 - val_accuracy: 0.9729\nEpoch 25/50\n189/189 [==============================] - 26s 138ms/step - loss: 0.0941 - accuracy: 0.9727 - val_loss: 0.0540 - val_accuracy: 0.9843\nEpoch 26/50\n189/189 [==============================] - 27s 142ms/step - loss: 0.0774 - accuracy: 0.9780 - val_loss: 0.0540 - val_accuracy: 0.9852\nEpoch 27/50\n189/189 [==============================] - 27s 142ms/step - loss: 0.0684 - accuracy: 0.9805 - val_loss: 0.0556 - val_accuracy: 0.9836\nEpoch 28/50\n189/189 [==============================] - 26s 139ms/step - loss: 0.0666 - accuracy: 0.9812 - val_loss: 0.0410 - val_accuracy: 0.9869\nEpoch 29/50\n189/189 [==============================] - 26s 140ms/step - loss: 0.0652 - accuracy: 0.9815 - val_loss: 0.0536 - val_accuracy: 0.9840\nEpoch 30/50\n189/189 [==============================] - 27s 141ms/step - loss: 0.0566 - accuracy: 0.9839 - val_loss: 0.0531 - val_accuracy: 0.9821\nEpoch 31/50\n189/189 [==============================] - 26s 136ms/step - loss: 0.0589 - accuracy: 0.9833 - val_loss: 0.0508 - val_accuracy: 0.9857\nEpoch 32/50\n189/189 [==============================] - 27s 140ms/step - loss: 0.0562 - accuracy: 0.9834 - val_loss: 0.0472 - val_accuracy: 0.9860\nEpoch 33/50\n189/189 [==============================] - 26s 138ms/step - loss: 0.0524 - accuracy: 0.9844 - val_loss: 0.0524 - val_accuracy: 0.9848\nEpoch 34/50\n189/189 [==============================] - 27s 142ms/step - loss: 0.0536 - accuracy: 0.9848 - val_loss: 0.3008 - val_accuracy: 0.9431\nEpoch 35/50\n189/189 [==============================] - 27s 141ms/step - loss: 0.1335 - accuracy: 0.9652 - val_loss: 0.1144 - val_accuracy: 0.9738\nEpoch 36/50\n189/189 [==============================] - 26s 137ms/step - loss: 0.0663 - accuracy: 0.9810 - val_loss: 0.0436 - val_accuracy: 0.9867\nEpoch 37/50\n189/189 [==============================] - 27s 141ms/step - loss: 0.0561 - accuracy: 0.9840 - val_loss: 0.0346 - val_accuracy: 0.9905\nEpoch 38/50\n189/189 [==============================] - 27s 142ms/step - loss: 0.0487 - accuracy: 0.9852 - val_loss: 0.0384 - val_accuracy: 0.9881\nEpoch 39/50\n189/189 [==============================] - 26s 139ms/step - loss: 0.0464 - accuracy: 0.9865 - val_loss: 0.0538 - val_accuracy: 0.9867\nEpoch 40/50\n189/189 [==============================] - 27s 142ms/step - loss: 0.0501 - accuracy: 0.9853 - val_loss: 0.0339 - val_accuracy: 0.9893\nEpoch 41/50\n189/189 [==============================] - 27s 143ms/step - loss: 0.0477 - accuracy: 0.9861 - val_loss: 0.0463 - val_accuracy: 0.9860\nEpoch 42/50\n189/189 [==============================] - 26s 138ms/step - loss: 0.0521 - accuracy: 0.9847 - val_loss: 0.0337 - val_accuracy: 0.9876\nEpoch 43/50\n189/189 [==============================] - 27s 141ms/step - loss: 0.0447 - accuracy: 0.9869 - val_loss: 0.0324 - val_accuracy: 0.9898\nEpoch 44/50\n189/189 [==============================] - 27s 142ms/step - loss: 0.0475 - accuracy: 0.9864 - val_loss: 0.0724 - val_accuracy: 0.9812\nEpoch 45/50\n189/189 [==============================] - 27s 141ms/step - loss: 0.0469 - accuracy: 0.9872 - val_loss: 0.0606 - val_accuracy: 0.9838\nEpoch 46/50\n189/189 [==============================] - 27s 143ms/step - loss: 0.0455 - accuracy: 0.9867 - val_loss: 0.0409 - val_accuracy: 0.9874\nEpoch 47/50\n189/189 [==============================] - 27s 142ms/step - loss: 0.0439 - accuracy: 0.9877 - val_loss: 0.0375 - val_accuracy: 0.9886\nEpoch 48/50\n189/189 [==============================] - 27s 142ms/step - loss: 0.0449 - accuracy: 0.9877 - val_loss: 0.0564 - val_accuracy: 0.9843\nEpoch 49/50\n189/189 [==============================] - 27s 142ms/step - loss: 0.0449 - accuracy: 0.9871 - val_loss: 0.0532 - val_accuracy: 0.9881\nEpoch 50/50\n189/189 [==============================] - 27s 143ms/step - loss: 0.0495 - accuracy: 0.9858 - val_loss: 349.1444 - val_accuracy: 0.8169\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Predictions | Ensembling","metadata":{}},{"cell_type":"code","source":"predictions_1 = model.predict(test_images)\npredictions_2 = model_2.predict(test_images)","metadata":{"execution":{"iopub.status.busy":"2023-06-26T20:27:16.628837Z","iopub.execute_input":"2023-06-26T20:27:16.629209Z","iopub.status.idle":"2023-06-26T20:27:35.077611Z","shell.execute_reply.started":"2023-06-26T20:27:16.629180Z","shell.execute_reply":"2023-06-26T20:27:35.076401Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"875/875 [==============================] - 5s 5ms/step\n875/875 [==============================] - 9s 9ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions = (predictions_1 + predictions_2) / 2","metadata":{"execution":{"iopub.status.busy":"2023-06-26T20:27:42.095065Z","iopub.execute_input":"2023-06-26T20:27:42.095437Z","iopub.status.idle":"2023-06-26T20:27:42.105352Z","shell.execute_reply.started":"2023-06-26T20:27:42.095408Z","shell.execute_reply":"2023-06-26T20:27:42.104252Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"sub = [np.argmax(pred) for pred in predictions]","metadata":{"execution":{"iopub.status.busy":"2023-06-26T20:27:45.587502Z","iopub.execute_input":"2023-06-26T20:27:45.588433Z","iopub.status.idle":"2023-06-26T20:27:45.698363Z","shell.execute_reply.started":"2023-06-26T20:27:45.588388Z","shell.execute_reply":"2023-06-26T20:27:45.697411Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"sub","metadata":{"execution":{"iopub.status.busy":"2023-06-26T17:07:45.409945Z","iopub.execute_input":"2023-06-26T17:07:45.410302Z","iopub.status.idle":"2023-06-26T17:07:45.440715Z","shell.execute_reply.started":"2023-06-26T17:07:45.410272Z","shell.execute_reply":"2023-06-26T17:07:45.439656Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"[2,\n 0,\n 9,\n 0,\n 3,\n 7,\n 0,\n 3,\n 0,\n 3,\n 5,\n 7,\n 4,\n 0,\n 4,\n 3,\n 3,\n 1,\n 9,\n 0,\n 9,\n 1,\n 1,\n 5,\n 7,\n 4,\n 2,\n 7,\n 4,\n 7,\n 7,\n 5,\n 4,\n 2,\n 6,\n 2,\n 5,\n 5,\n 1,\n 6,\n 7,\n 7,\n 4,\n 9,\n 8,\n 7,\n 8,\n 2,\n 6,\n 7,\n 6,\n 8,\n 8,\n 3,\n 8,\n 2,\n 1,\n 2,\n 2,\n 0,\n 4,\n 1,\n 7,\n 0,\n 0,\n 0,\n 1,\n 9,\n 0,\n 1,\n 6,\n 5,\n 8,\n 8,\n 2,\n 8,\n 9,\n 9,\n 2,\n 3,\n 5,\n 4,\n 1,\n 0,\n 9,\n 2,\n 4,\n 3,\n 6,\n 7,\n 2,\n 0,\n 6,\n 6,\n 1,\n 4,\n 3,\n 9,\n 7,\n 4,\n 0,\n 9,\n 2,\n 0,\n 7,\n 3,\n 0,\n 5,\n 0,\n 8,\n 0,\n 0,\n 4,\n 7,\n 1,\n 7,\n 1,\n 1,\n 3,\n 3,\n 3,\n 7,\n 2,\n 8,\n 6,\n 3,\n 8,\n 7,\n 7,\n 4,\n 3,\n 5,\n 6,\n 0,\n 0,\n 0,\n 3,\n 1,\n 3,\n 6,\n 4,\n 3,\n 4,\n 5,\n 5,\n 8,\n 7,\n 7,\n 2,\n 8,\n 4,\n 3,\n 5,\n 6,\n 5,\n 3,\n 7,\n 5,\n 7,\n 8,\n 3,\n 0,\n 4,\n 5,\n 1,\n 3,\n 7,\n 6,\n 3,\n 0,\n 2,\n 7,\n 8,\n 6,\n 1,\n 3,\n 7,\n 4,\n 1,\n 2,\n 4,\n 8,\n 5,\n 2,\n 4,\n 9,\n 2,\n 1,\n 6,\n 0,\n 6,\n 1,\n 4,\n 9,\n 6,\n 0,\n 9,\n 7,\n 6,\n 9,\n 1,\n 9,\n 0,\n 9,\n 9,\n 0,\n 8,\n 4,\n 6,\n 2,\n 0,\n 9,\n 3,\n 6,\n 3,\n 2,\n 1,\n 6,\n 3,\n 4,\n 2,\n 3,\n 1,\n 2,\n 2,\n 0,\n 4,\n 6,\n 1,\n 0,\n 0,\n 4,\n 9,\n 1,\n 7,\n 3,\n 2,\n 3,\n 8,\n 6,\n 8,\n 6,\n 2,\n 8,\n 5,\n 5,\n 4,\n 8,\n 3,\n 5,\n 9,\n 7,\n 1,\n 3,\n 8,\n 4,\n 5,\n 1,\n 4,\n 5,\n 6,\n 3,\n 3,\n 5,\n 7,\n 0,\n 6,\n 8,\n 3,\n 1,\n 6,\n 0,\n 6,\n 3,\n 9,\n 5,\n 1,\n 5,\n 8,\n 4,\n 0,\n 9,\n 2,\n 0,\n 5,\n 3,\n 7,\n 1,\n 9,\n 9,\n 5,\n 7,\n 7,\n 9,\n 9,\n 6,\n 3,\n 0,\n 3,\n 3,\n 6,\n 9,\n 8,\n 2,\n 6,\n 3,\n 7,\n 1,\n 4,\n 5,\n 8,\n 5,\n 9,\n 0,\n 0,\n 3,\n 8,\n 4,\n 1,\n 8,\n 4,\n 1,\n 1,\n 9,\n 8,\n 4,\n 5,\n 1,\n 5,\n 3,\n 6,\n 3,\n 1,\n 3,\n 0,\n 9,\n 0,\n 0,\n 6,\n 0,\n 6,\n 3,\n 1,\n 8,\n 6,\n 0,\n 6,\n 5,\n 2,\n 2,\n 6,\n 7,\n 7,\n 2,\n 5,\n 8,\n 3,\n 9,\n 2,\n 7,\n 8,\n 6,\n 3,\n 8,\n 4,\n 2,\n 3,\n 8,\n 1,\n 6,\n 4,\n 8,\n 7,\n 9,\n 7,\n 6,\n 9,\n 5,\n 3,\n 7,\n 6,\n 5,\n 5,\n 4,\n 2,\n 6,\n 2,\n 1,\n 3,\n 7,\n 1,\n 7,\n 9,\n 9,\n 6,\n 1,\n 1,\n 1,\n 7,\n 3,\n 9,\n 7,\n 6,\n 1,\n 1,\n 1,\n 9,\n 3,\n 8,\n 5,\n 5,\n 0,\n 4,\n 1,\n 2,\n 3,\n 1,\n 1,\n 3,\n 5,\n 9,\n 6,\n 6,\n 5,\n 3,\n 1,\n 4,\n 7,\n 4,\n 7,\n 4,\n 8,\n 5,\n 2,\n 6,\n 1,\n 3,\n 9,\n 5,\n 0,\n 8,\n 4,\n 7,\n 4,\n 4,\n 4,\n 1,\n 5,\n 3,\n 9,\n 9,\n 7,\n 6,\n 9,\n 5,\n 9,\n 2,\n 3,\n 5,\n 6,\n 6,\n 7,\n 5,\n 0,\n 5,\n 1,\n 7,\n 4,\n 4,\n 1,\n 1,\n 4,\n 9,\n 5,\n 6,\n 0,\n 1,\n 3,\n 1,\n 0,\n 4,\n 8,\n 1,\n 2,\n 7,\n 9,\n 4,\n 8,\n 3,\n 7,\n 7,\n 4,\n 2,\n 4,\n 6,\n 7,\n 6,\n 3,\n 2,\n 0,\n 6,\n 5,\n 9,\n 4,\n 1,\n 8,\n 3,\n 3,\n 0,\n 2,\n 7,\n 6,\n 8,\n 7,\n 5,\n 3,\n 5,\n 7,\n 4,\n 3,\n 6,\n 9,\n 0,\n 7,\n 7,\n 1,\n 0,\n 1,\n 1,\n 7,\n 0,\n 5,\n 3,\n 8,\n 3,\n 5,\n 6,\n 5,\n 4,\n 3,\n 0,\n 2,\n 8,\n 2,\n 0,\n 3,\n 0,\n 9,\n 2,\n 1,\n 1,\n 3,\n 0,\n 5,\n 5,\n 0,\n 7,\n 5,\n 6,\n 2,\n 0,\n 3,\n 8,\n 1,\n 6,\n 5,\n 4,\n 1,\n 1,\n 4,\n 6,\n 5,\n 3,\n 6,\n 0,\n 4,\n 8,\n 2,\n 4,\n 2,\n 5,\n 1,\n 7,\n 6,\n 9,\n 1,\n 7,\n 3,\n 8,\n 0,\n 8,\n 8,\n 4,\n 5,\n 3,\n 6,\n 6,\n 6,\n 0,\n 3,\n 5,\n 1,\n 7,\n 1,\n 6,\n 2,\n 8,\n 5,\n 6,\n 4,\n 7,\n 4,\n 3,\n 3,\n 2,\n 4,\n 7,\n 0,\n 0,\n 9,\n 8,\n 5,\n 9,\n 4,\n 0,\n 8,\n 8,\n 3,\n 6,\n 2,\n 6,\n 1,\n 8,\n 6,\n 1,\n 4,\n 7,\n 7,\n 8,\n 3,\n 0,\n 9,\n 9,\n 6,\n 7,\n 7,\n 4,\n 8,\n 1,\n 8,\n 4,\n 8,\n 0,\n 2,\n 8,\n 2,\n 4,\n 3,\n 3,\n 7,\n 2,\n 3,\n 4,\n 0,\n 4,\n 8,\n 1,\n 3,\n 3,\n 6,\n 3,\n 9,\n 4,\n 3,\n 8,\n 7,\n 7,\n 2,\n 6,\n 0,\n 6,\n 9,\n 8,\n 8,\n 1,\n 3,\n 4,\n 6,\n 9,\n 9,\n 2,\n 6,\n 0,\n 1,\n 8,\n 4,\n 3,\n 9,\n 8,\n 8,\n 4,\n 0,\n 5,\n 0,\n 6,\n 0,\n 4,\n 4,\n 6,\n 5,\n 1,\n 8,\n 1,\n 5,\n 3,\n 6,\n 2,\n 3,\n 7,\n 8,\n 9,\n 3,\n 1,\n 0,\n 1,\n 0,\n 6,\n 4,\n 7,\n 5,\n 7,\n 1,\n 3,\n 2,\n 7,\n 7,\n 1,\n 5,\n 1,\n 5,\n 4,\n 4,\n 3,\n 4,\n 3,\n 9,\n 0,\n 7,\n 8,\n 6,\n 4,\n 9,\n 4,\n 4,\n 1,\n 4,\n 7,\n 1,\n 1,\n 8,\n 3,\n 0,\n 4,\n 0,\n 4,\n 0,\n 0,\n 5,\n 1,\n 8,\n 6,\n 5,\n 0,\n 1,\n 5,\n 3,\n 4,\n 6,\n 3,\n 1,\n 1,\n 6,\n 9,\n 8,\n 3,\n 5,\n 5,\n 4,\n 8,\n 8,\n 5,\n 0,\n 4,\n 0,\n 4,\n 3,\n 1,\n 6,\n 9,\n 9,\n 1,\n 1,\n 3,\n 3,\n 1,\n 4,\n 9,\n 6,\n 9,\n 1,\n 5,\n 4,\n 2,\n 3,\n 2,\n 4,\n 0,\n 9,\n 7,\n 4,\n 3,\n 0,\n 5,\n 0,\n 1,\n 9,\n 0,\n 4,\n 5,\n 2,\n 8,\n 0,\n 5,\n 9,\n 3,\n 9,\n 6,\n 1,\n 5,\n 5,\n 1,\n 9,\n 0,\n 8,\n 2,\n 6,\n 7,\n 2,\n 8,\n 5,\n 8,\n 9,\n 7,\n 7,\n 2,\n 8,\n 1,\n 3,\n 4,\n 5,\n 0,\n 4,\n 1,\n 4,\n 2,\n 3,\n 6,\n 9,\n 2,\n 3,\n 4,\n 5,\n 4,\n 2,\n 3,\n 3,\n 1,\n 1,\n 0,\n 1,\n 4,\n 9,\n 1,\n 1,\n 2,\n 7,\n 1,\n 5,\n 4,\n 9,\n 1,\n 7,\n 6,\n 0,\n 4,\n 2,\n 9,\n 4,\n 1,\n 1,\n 5,\n 3,\n 5,\n 7,\n 9,\n 7,\n 8,\n 3,\n 2,\n 7,\n 2,\n 0,\n 4,\n 7,\n 1,\n 6,\n 4,\n 6,\n 1,\n 5,\n 7,\n 3,\n 5,\n 9,\n 4,\n 7,\n 9,\n 6,\n 6,\n 3,\n 3,\n 2,\n 1,\n 4,\n 5,\n 3,\n 7,\n 7,\n 9,\n 5,\n 6,\n 2,\n 6,\n 1,\n 0,\n 9,\n 3,\n 2,\n 9,\n 2,\n 6,\n 7,\n 5,\n 2,\n 3,\n 2,\n 8,\n 3,\n 0,\n 2,\n 7,\n 9,\n 4,\n 0,\n 9,\n 5,\n 1,\n 8,\n 8,\n 5,\n 3,\n 2,\n 9,\n 6,\n 7,\n 0,\n 8,\n 0,\n 7,\n 4,\n 5,\n 8,\n 7,\n 9,\n 7,\n 7,\n 0,\n 5,\n 3,\n 2,\n 1,\n 9,\n 0,\n 6,\n 8,\n 3,\n 6,\n 2,\n 2,\n 9,\n ...]"},"metadata":{}}]},{"cell_type":"code","source":"sampe_sub = pd.read_csv(\"/kaggle/input/digit-recognizer/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-06-26T20:28:02.232914Z","iopub.execute_input":"2023-06-26T20:28:02.233589Z","iopub.status.idle":"2023-06-26T20:28:02.258298Z","shell.execute_reply.started":"2023-06-26T20:28:02.233534Z","shell.execute_reply":"2023-06-26T20:28:02.257362Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"for i,el in enumerate(sub):\n    sampe_sub.iloc[i,1] = el","metadata":{"execution":{"iopub.status.busy":"2023-06-26T20:28:06.450108Z","iopub.execute_input":"2023-06-26T20:28:06.450467Z","iopub.status.idle":"2023-06-26T20:28:08.133221Z","shell.execute_reply.started":"2023-06-26T20:28:06.450438Z","shell.execute_reply":"2023-06-26T20:28:08.132215Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"sampe_sub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-26T20:28:33.593815Z","iopub.execute_input":"2023-06-26T20:28:33.594162Z","iopub.status.idle":"2023-06-26T20:28:33.653425Z","shell.execute_reply.started":"2023-06-26T20:28:33.594134Z","shell.execute_reply":"2023-06-26T20:28:33.652511Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"sampe_sub.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-26T17:08:07.946435Z","iopub.execute_input":"2023-06-26T17:08:07.946834Z","iopub.status.idle":"2023-06-26T17:08:07.966906Z","shell.execute_reply.started":"2023-06-26T17:08:07.946790Z","shell.execute_reply":"2023-06-26T17:08:07.965713Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"   ImageId  Label\n0        1      2\n1        2      0\n2        3      9\n3        4      0\n4        5      3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}
